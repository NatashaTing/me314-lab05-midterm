---
title: "Midterm Assignemnt, ME314 2019"
author: "TING, Zet Ping"
output: 
    html_document: 
    df_print: paged
---

![](images/lse-logo.jpg)

#### Summer School 2019 midsession examination  

# ME314 Introduction to Data Science and Machine Learning 

## Suitable for all candidates


### Instructions to candidates  

* Complete the assignment by adding your answers directly to the RMarkdown document, knitting the document, and submitting the HTML file to Moodle.   
* Time allowed: due 19:00 on Wednesday, 7th August 2019.  
* Submit the assignment via [Moodle](https://shortcourses.lse.ac.uk/course/view.php?id=158).

## Question 1:

This question should be answered using the `Carseats` data set, which is part of the **ISLR** package. This data contains simulated data set containing sales of child car seats at 400 different stores.

```{r importstatements, results='hide', warning=FALSE}

# load required packages
PKGs <- c("class","ISLR","dplyr","ggplot2", "rowr", "caret")

suppressPackageStartupMessages(
  lapply(
    PKGs, library, warn.conflicts = FALSE, character.only = TRUE ,quietly = T
    )
  )

```

***
##### 1.  Fit a regression model predicting Sales using Advertising and Price as predictors.  Interpret the coefficients, the $R^2$, and the Residual standard error from the regression (by explaining each in a few statements).

```{r q1_a}

data(Carseats)

lm.fit1 <- lm(Sales ~ Advertising + Price, data = Carseats)

summary(lm.fit1)
```

<p style="background-color:#e6ffe6; padding: 3%">
An increase of 1 thousand dollars in local **advertising** budget is associated with `0.12` increase in unit sales of car seats, for a given price of the product. Meanwhile, a one-dollar increase in the **price** of car seats is associated with a drop in sales by `0.05` unit, holding advertising budget constant. Together, this model explains `28.2%` of the variation in sales. The total distance between estimated and real values (sum of squared residual, **RSS**), has been minimised at `2.399`. 
</p>
  
    
***  
  
  
##### 2.  Fit a second model by adding Urban as an interactive variable with Advertising.  Interpret the two new coefficients produced by adding this interaction to the Advertising variable that was already present from the first question, in a few statements.

```{r q1_b}

lm.fit2 <- lm(Sales ~ Advertising * Urban + Price, data = Carseats)

summary(lm.fit2)

```

<ul style="background-color:#e6ffe6; padding: 3%">
  <li>For **urban stores**, an additional thousand dollar increase in advertising budget is associated with 0.128015 + -0.006666 = `0.121349`, which is a **0.12 decrease in unit sales**. </li>
  <li>For **non-urban stores**, an additional thousand dollar increase in advertising budget is associated with 0.128015, which is a **0.13 rise in unit sales**.</li>
</ul>


  
    
***    

##### 3.  Which of these two models is preferable, and why?  

```{r q1_c}
anova(lm.fit1, lm.fit2)
```

<ul style="background-color:#e6ffe6; padding: 3%">
  <li>Between these two models, the one without interaction term is preferred. </li>
  
  <li>The **second model is less preferred** because: </li>  
    <ol>
      <li>the interaction term and new main effect `Urban` term both have **high p-values** and are **not statistically significant**; </li>
      <ul><li>we **fail to reject the null hypothesis in ANOVA** where  
    $$H_0: \widehat{\beta}_\text{Urban} == \widehat{\beta}_\text{Urban*Advertising} == 0$$</li></ul>
      <li>there is **no noticable increase in model explanatory power** from including interaction term, with $R^2$ constant at `0.2819`when rounded;  </li>
      <li>**adjusted-$R^2$ is lower** because of penalty from including 2 more variables.  </li>
      
    </ol>
</ul>
  
  
  
## Question 2:

You will need to load the core library for the course textbook and any other libraries you find suitable to answer the question: 


This question should be answered using the `Weekly` data set, which is part of the **ISLR** package. This data contains 1,089 weekly stock returns for 21 years, from the beginning of 1990 to the end of 2010.

#### 1.   Perform exploratory data analysis of the `Weekly` data (produce some numerical and graphical summaries). Discuss any patterns that emerge. 

```{r q2_a_explore}
data(Weekly)

attach(Weekly)

sum(is.na(Weekly))      # = 0

summary(dplyr::select_if(Weekly, is.numeric))   

# check how many weeks are included in each year
count_by_years <- group_by(Weekly, Year) %>% 
                                    summarise(n = n())

count_by_years


# ---- explore Lagged returns
# generate a correlation matrix between the lag variables 
corr.mat <- dplyr::select(Weekly, -Direction) %>%
          dplyr::mutate(as.numeric(Direction)) %>%
                      cor() %>% 
                      round(3) 
corr.mat

```

```{r}
# plot the correlation between the lag variables
plot(corr.mat[which(rownames(corr.mat)=="Lag2"), -which(rownames(corr.mat)=="Lag2")], 
              type="b", col=2,xlab="index (other variable)", ylab="correlation")
lines(corr.mat[which(rownames(corr.mat)=="Lag1"),-which(rownames(corr.mat)=="Lag1")],
              type="b", col=3, ylab="")
lines(corr.mat[which(rownames(corr.mat)=="Lag3"),-which(rownames(corr.mat)=="Lag3")], 
              type="b", col=4, ylab="")
lines(corr.mat[which(rownames(corr.mat)=="Lag4"),-which(rownames(corr.mat)=="Lag4")], 
              type="b", col=5, ylab="")
lines(corr.mat[which(rownames(corr.mat)=="Lag5"),-which(rownames(corr.mat)=="Lag5")], 
              type="b", col=6)
legend("bottomright", legend = c("Lag2", "Lag1", "Lag3", "Lag4", "Lag5"), 
       col = 2:6, lwd = 2)

```

```{r}

# ---- explore Direction

plot(Today, Direction)
abline( v = 0 , col = "red")

ggplot(data = Weekly)  + 
  geom_point(mapping = aes(x = Year, y = Volume)) + 
  geom_smooth(mapping = aes(x = Year, y = Volume), col="red")


print(mean(as.numeric(Direction)))

```

<ul style="background-color:#e6ffe6; padding: 3%">
  ##### Observation 
  <li> Data is dated from 1990 to 2010.</li>  
  
  <li> **Returns**
    <ul>
      <li>From the correlation matrix plot, a lot of the **lag variables are correlated** with percentage returns from 2 weeks (periods) before them. </li>
      <li>However, the autocorrelation pattern is erratic. There is no other clear trend.</li>
    </ul>
  </li>
  
  <li> **`Volume` **
    <ul> 
    <li>`Volume` traded per day is **highly variant** week-to-week. Its standard deviation is `(sd(Volume) / mean(Volume)) %>% round(2)` = `1.07` times its mean of `1.57`.  </li>
    <li>This means that on average, for any given week we can expect the next week's volume to be 1.68 billion shares more or less than the previous week. </li>
    <li>Volume also exhibits an **increasing trend over time**. </li>
    </ul>
  </li>
  
  <li>**`Direction`**
    <ul>
      <li>Direction seems to be evaluated relative to the percentage for this week. Therefore, `Direction` will cause a **perfect separation** in regression. </li>
      <li>The only factor variable in the dataset `Direction`, has two levels. Because investors may have a preference for the "Up" movement, a logistic regression of it may have **class imbalance** concerns. </li>
      <li>There is **more bullish days** than bearish days in this dataset. </li>
    </ul>
  </li>
</ul>

  
    
    
#### 2. Fit a logistic regression with `Direction` as the response and different combinations of lag variables plus `Volume` as predictors. Use the period from 1990 to 2008 as your training set and 2009-2010 as your test set. Produce a summary of results. 

    Do any of the predictors appear to be statistically significant in your training set? If so, which ones?
    

```{r}

Weekly.test <- Weekly %>% dplyr::filter(Year %in% c(2009,2010))
Weekly.train <- Weekly %>% dplyr::filter(!Year %in% c(2009, 2010))

# test if sensible after splitting
isTRUE(nrow(Weekly.train) + nrow(Weekly.test) == nrow(Weekly))
isTRUE(ncol(Weekly.train) == ncol(Weekly.test))

logit.fit_all <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume , 
                 family = "binomial", 
                 data = Weekly.train)

logit.fit_notf4 <- glm(Direction ~ Year + Lag1 + Lag2 + Lag3 + Lag4 + Volume,
                      family = "binomial",
                      data = Weekly.train)

logit.fit_notf3 <- glm(Direction ~ Year + Lag1 + Lag2 + Lag3 + Volume,
                      family = "binomial",
                      data = Weekly.train)

logit.fit_notf2 <- glm(Direction ~ Year + Lag1 + Lag2 + Volume,
                      family = "binomial",
                      data = Weekly.train)

logit.fit_notf1 <- glm(Direction ~ Year + Lag1 + Volume,
                      family = "binomial",
                      data = Weekly.train)

logit.fit_nolag <- glm(Direction ~ Year + Volume,
                      family = "binomial",
                      data = Weekly.train)

allfit <- c(logit.fit_all, logit.fit_notf4, logit.fit_notf3, logit.fit_notf2, logit.fit_notf1, logit.fit_nolag)

# get list of p-values
logit.fit_allp <- summary(logit.fit_all)$coefficients[,4]
logit.fit_notf4p <- summary(logit.fit_notf4)$coefficients[,4]
logit.fit_notf3p <- summary(logit.fit_notf3)$coefficients[,4]
logit.fit_notf2p <- summary(logit.fit_notf2)$coefficients[,4]
logit.fit_notf1p <- summary(logit.fit_notf1)$coefficients[,4]
logit.fit_nolagp <- summary(logit.fit_nolag)$coefficients[,4]

# this is a table of p-values
tryll <- cbind.fill(logit.fit_allp, logit.fit_notf4p, logit.fit_notf3p, 
                    logit.fit_notf2p,logit.fit_notf1p, logit.fit_nolagp, fill = NA)

# intercept aside, it looks like only Lag1 is slightly signif. (p value 0.03)
tryll

# verify that table is correcly representing p-values from logistic fit
summary(logit.fit_all)
logit.fit_allp[2]         

```

<p style="background-color:#e6ffe6; padding: 3%">
Only `Lag1` is moderately significant with a p-value of 0.03, when `Direction` is regressed on all other lag variables and trade `Volume` on a logistic regression. 
</p>

  
    
      
      
#### 3.  From your test set, compute the confusion matrix, and calculate accuracy, precision, recall and F1. 
     
    Explain what the confusion matrix is telling you about the types of mistakes made by logistic regression, and what can you learn from additional measures of fit like accuracy, precision, recall, and F1.

```{r}

logit.fit_all_model <- train(
  Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, 
  data = Weekly.train, 
  method = "glm",
  family = "binomial",
  trControl = trainControl(method = "cv", number = 10))

pred_class <- predict(logit.fit_all_model, Weekly.train)

confusionMatrix(
  mode = "prec_recall",
  data = relevel(pred_class, ref = "Up"), 
  reference = relevel(Weekly.train$Direction, ref = "Up")
)

```

<p style="background-color:#e6ffe6; padding: 3%">
The confusion matrix shows that the model **predicted correctly 554 times** in total. The model made **431 incorrect predictions** in total: in **361** occasions having predicted "Up" when market is down; and **70** times predicted "Down" when market goes up. 
</p>

<ol style="background-color:#e6ffe6; padding: 3%">

  <li>**Accuracy** = `0.5624 ` 
    <ul>
      <li>`554` Correct gueses / `985` Total Predictions</li>
      <li> **Model is correct in its prediction 56% of the time.** </>
    </ul>
  </li>
  
  <li>**Sensitivity** (a.k.a. **Recall**, True Positive Rate ) = `0.8713`
    <ul>
      <li> `1` - False Positive = `1` - (`70` / `544`) = `1` - `0.1287` = `0.8713`</li>
      <li> `474` True Positive / `544` Total True Positive = `0.8713` </li>
      <li> **The model correctly predicted 87% of the number of total bullish weeks.** </li>
    </ul>
  </li>
  
  <li>**Specificity** (a.k.a. true negative rate) = `0.1814`
    <ul>
      <li>`80` True Negative / `441` Total True Negative = `0.1814`</li>
      <li>The model only correctly predicted 18% of the number of total bearish weeks. This means that **82% of the times, it wrongly predicted that the market would up when it actually went down.** Because of class imbalance this is likely drastic. </li>
    </ul>
  </li>
  
  <li>**Precision** = `0.5677` 
    <ul>
      <li>Def: `474` True Positive / (`474` True Positive + `361` False Positive)] </li>
      <li> `474` / `835` = 0.5677 </li>
      <li>**The model correctly predicted 87% of the number of total bullish weeks.**</li>
    </ul>
  </li>
  
  <li>**F1** = `0.6875` 
    <ul>
      <li>F1 = 2 * [(Precision * Recall) / (Precision + Recall)] </li>
      <li>2 * [(0.5677 * 0.8713) / (0.5677 + 0.8713)]</li>
    </ul>
  </li>
  
</ol>

  
  
#### 4.  (Extra credit) Experiment with alternative classification methods. 
  Present the results of your experiments reporting method, associated confusion matrix, and measures of fit on the test set like accuracy, precision, recall, and F1.
    
    
```{r import_for_tree}

# Modeling packages
library(rpart)       # direct engine for decision tree application
library(rpart.plot)  # for plotting decision trees
library(vip)         # for feature importance
library(pdp)         # for feature effects

```

```{r Q2-decisiontree}

weekly_dt1 <- rpart(
  formula = Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume,
  data    = Weekly.train,
  method = "class"
) 

rpart.plot(weekly_dt1)

plotcp(weekly_dt1)

pre_class_dt1 <- predict(weekly_dt1, Weekly.train, type="class")

confusionMatrix(
  mode = "prec_recall",
  data = relevel(pre_class_dt1, ref = "Up"), 
  reference = relevel(Weekly.train$Direction, ref = "Up")
)

```
  
<p style="background-color:#e6ffe6; padding: 3%">

</p>

```{r Q2-bagging}

library(randomForest)
library(ipred)       # for fitting bagged decision trees

set.seed(123)

# train bagged model
week_bag1 <- bagging(
  formula = Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume,
  data = Weekly.train,
  nbagg = 100,  
  coob = TRUE,
  control = rpart.control(minsplit = 2, cp = 0)
)

pred_class_bag1 <- predict(week_bag1, method="class", Weekly.train)


confusionMatrix(
  mode = "prec_recall",
  data = relevel(pred_class_bag1, ref = "Up"), 
  reference = relevel(Weekly.train$Direction, ref = "Up")
)


```
    
<p style="background-color:#e6ffe6; padding: 3%">
</p>

```{r randomForest}

rf.weekly <-  randomForest(Direction ~ . -Today, 
                           data=Weekly.train, 
                           mtry=2)

pred_class_rf1 <-  predict(rf.weekly, data = Weekly.test, method="class")

# get Mean error
mean(pred_class_rf1 != Weekly.test$Direction)

# get OOB RMSE
# OOB estimate of  error rate: 47.21%

confusionMatrix(
  mode = "prec_recall",
  data = relevel(pred_class_rf1, ref = "Up"), 
  reference = relevel(Weekly.train$Direction, ref = "Up")
)



```
